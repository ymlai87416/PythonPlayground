{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ymlai\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "import seaborn as sns\n",
    "from six.moves import cPickle as pickle\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From previous result\n",
    "\n",
    "From previous result, we decide to use the following models to do submission. They are:\n",
    "1. Multinominal Naive bayes Accuracy: 84.33%\n",
    "2. XGboost Accuracy: 83.58%\n",
    "3. Logistic Accuracy: 83.21%\n",
    "\n",
    "In this section, we will run a grid search to find the best parameter for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_0</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_0</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>...</th>\n",
       "      <th>AgeDiscrete_8</th>\n",
       "      <th>AgeDiscrete_9</th>\n",
       "      <th>FareDiscrete_0</th>\n",
       "      <th>FareDiscrete_1</th>\n",
       "      <th>FareDiscrete_2</th>\n",
       "      <th>FareDiscrete_3</th>\n",
       "      <th>FareDiscrete_4</th>\n",
       "      <th>FareDiscrete_5</th>\n",
       "      <th>FareDiscrete_6</th>\n",
       "      <th>FareDiscrete_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass_0  Pclass_1  Pclass_2  Sex_0  Sex_1  SibSp_0  SibSp_1  \\\n",
       "PassengerId                                                                 \n",
       "1                   0         0         1      0      1        0        1   \n",
       "2                   1         0         0      1      0        0        1   \n",
       "3                   0         0         1      1      0        1        0   \n",
       "4                   1         0         0      1      0        0        1   \n",
       "5                   0         0         1      0      1        1        0   \n",
       "6                   0         0         1      0      1        1        0   \n",
       "7                   1         0         0      0      1        1        0   \n",
       "8                   0         0         1      0      1        0        0   \n",
       "9                   0         0         1      1      0        1        0   \n",
       "10                  0         1         0      1      0        0        1   \n",
       "\n",
       "             SibSp_2  SibSp_3  SibSp_4       ...        AgeDiscrete_8  \\\n",
       "PassengerId                                  ...                        \n",
       "1                  0        0        0       ...                    0   \n",
       "2                  0        0        0       ...                    0   \n",
       "3                  0        0        0       ...                    0   \n",
       "4                  0        0        0       ...                    0   \n",
       "5                  0        0        0       ...                    0   \n",
       "6                  0        0        0       ...                    0   \n",
       "7                  0        0        0       ...                    0   \n",
       "8                  0        1        0       ...                    0   \n",
       "9                  0        0        0       ...                    0   \n",
       "10                 0        0        0       ...                    0   \n",
       "\n",
       "             AgeDiscrete_9  FareDiscrete_0  FareDiscrete_1  FareDiscrete_2  \\\n",
       "PassengerId                                                                  \n",
       "1                        0               0               1               0   \n",
       "2                        0               0               0               1   \n",
       "3                        0               0               1               0   \n",
       "4                        0               0               0               1   \n",
       "5                        0               0               1               0   \n",
       "6                        0               0               1               0   \n",
       "7                        0               0               0               1   \n",
       "8                        0               0               1               0   \n",
       "9                        0               0               1               0   \n",
       "10                       0               0               1               0   \n",
       "\n",
       "             FareDiscrete_3  FareDiscrete_4  FareDiscrete_5  FareDiscrete_6  \\\n",
       "PassengerId                                                                   \n",
       "1                         0               0               0               0   \n",
       "2                         0               0               0               0   \n",
       "3                         0               0               0               0   \n",
       "4                         0               0               0               0   \n",
       "5                         0               0               0               0   \n",
       "6                         0               0               0               0   \n",
       "7                         0               0               0               0   \n",
       "8                         0               0               0               0   \n",
       "9                         0               0               0               0   \n",
       "10                        0               0               0               0   \n",
       "\n",
       "             FareDiscrete_7  \n",
       "PassengerId                  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "5                         0  \n",
       "6                         0  \n",
       "7                         0  \n",
       "8                         0  \n",
       "9                         0  \n",
       "10                        0  \n",
       "\n",
       "[10 rows x 78 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds_file = 'train_dataset.pickle'\n",
    "train_lb_file = 'train_label.pickle'\n",
    "test_ds_file = 'test_dataset.pickle'\n",
    "\n",
    "with open(train_ds_file, 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "    \n",
    "with open(train_lb_file, 'rb') as f:\n",
    "    train_label = pickle.load(f)\n",
    "    \n",
    "with open(test_ds_file, 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "    \n",
    "columns = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"FamilyMember\", \"Embarked\", \"Salutation\", \"CabinArea\", \"AgeDiscrete\", \"FareDiscrete\"]\n",
    "\n",
    "full_dataset = pandas.concat([train_dataset, test_dataset])\n",
    "\n",
    "full_datasett_onehot = pandas.get_dummies(full_dataset, sparse=True, columns=columns)\n",
    "\n",
    "train_dataset_onehot = full_datasett_onehot[:len(train_dataset)]\n",
    "test_dataset_onehot = full_datasett_onehot[len(train_dataset):]\n",
    "\n",
    "display(train_dataset_onehot[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_set(test_size):\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(train_dataset_onehot, train_label, test_size=test_size)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning logistic regression\n",
    "\n",
    "The model parameter to optimized are\n",
    "1. C - The regularization term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.25}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = {'C':[0.001, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1, 2.5, 5, 7.5]}\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, parameters)\n",
    "clf.fit(train_dataset_onehot, train_label)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, C:0.3 Accuracy: 80.60%\n",
      "Logistic regression, C:0.3 Accuracy: 83.58%\n",
      "Logistic regression, C:0.3 Accuracy: 82.46%\n",
      "Logistic regression, C:0.3 Accuracy: 81.72%\n",
      "Logistic regression, C:0.3 Accuracy: 80.97%\n",
      "Logistic regression, C:0.3 Accuracy: 79.85%\n",
      "Logistic regression, C:0.3 Accuracy: 81.34%\n",
      "Logistic regression, C:0.3 Accuracy: 83.21%\n",
      "Logistic regression, C:0.3 Accuracy: 79.10%\n",
      "Logistic regression, C:0.3 Accuracy: 80.60%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_set(0.3)\n",
    "    lr = LogisticRegression(C = 0.25)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"%s Accuracy: %.2f%%\" % (\"Logistic regression, C:0.3\", accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Multinominal Naive bayes\n",
    "\n",
    "The model parameter to optimized are\n",
    "\n",
    "1. alpha - The smoothing term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.75}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "parameters = {'alpha':[0.001, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1, 2.5, 5, 7.5]}\n",
    "mnb = MultinomialNB()\n",
    "clf = GridSearchCV(mnb, parameters)\n",
    "clf.fit(train_dataset_onehot, train_label)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 78.36%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 80.97%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 80.22%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 81.72%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 79.85%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 76.12%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 80.60%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 76.12%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 83.96%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 82.46%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_set(0.3)\n",
    "    lr = MultinomialNB(alpha = 0.75)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"%s Accuracy: %.2f%%\" % (\"Multinominal Naive bayes regression, alpha:0.001\", accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning XGBoost\n",
    "\n",
    "The model will use tree instead of linear\n",
    "\n",
    "The parameter to be tuned are:\n",
    "1. learning_rate\n",
    "2. max_depth\n",
    "3. min_child_weight\n",
    "4. gamma\n",
    "5. subsample\n",
    "6. colsample_bytree\n",
    "7. objective\n",
    "8. learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'reg_alpha': 0.1, 'colsample_bytree': 0.6, 'gamma': 0.2, 'min_child_weight': 2, 'max_depth': 3, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'min_child_weight':range(2,6,1),\n",
    "    'max_depth':range(3,7,1),\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "    'learning_rate':[0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "clf = RandomizedSearchCV(xgb, parameters, n_jobs=8, n_iter=5000)\n",
    "clf.fit(train_dataset_onehot, train_label)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 79.10%\n",
      "XGBoost Accuracy: 85.45%\n",
      "XGBoost Accuracy: 82.46%\n",
      "XGBoost Accuracy: 80.97%\n",
      "XGBoost Accuracy: 83.58%\n",
      "XGBoost Accuracy: 85.45%\n",
      "XGBoost Accuracy: 82.09%\n",
      "XGBoost Accuracy: 79.85%\n",
      "XGBoost Accuracy: 82.84%\n",
      "XGBoost Accuracy: 81.34%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_set(0.3)\n",
    "    lr = XGBClassifier(learning_rate=0.1, subsample=0.8, colsample_bytree=0.6, gamma=0.2,\n",
    "                       max_depth=3, reg_alpha=0.1, min_child_weight=2, objective= 'binary:logistic')\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"%s Accuracy: %.2f%%\" % (\"XGBoost\", accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Random Forest\n",
    "\n",
    "The parameter to be tuned are:\n",
    "1. max_depth\n",
    "2. max_features\n",
    "3. min_samples_split\n",
    "4. min_samples_leaf\n",
    "5. bootstrap\n",
    "6. criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 6, 'bootstrap': False, 'criterion': 'gini', 'n_estimators': 8, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "param_dist = {\"n_estimators\" : sp_randint(3, 20),\n",
    "              \"max_depth\": [1, 2, 3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 5000\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier()\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, n_jobs=8)\n",
    "random_search.fit(train_dataset_onehot, train_label)\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest Accuracy: 79.48%\n",
      "Random forest Accuracy: 79.85%\n",
      "Random forest Accuracy: 86.19%\n",
      "Random forest Accuracy: 80.60%\n",
      "Random forest Accuracy: 82.46%\n",
      "Random forest Accuracy: 82.46%\n",
      "Random forest Accuracy: 82.09%\n",
      "Random forest Accuracy: 79.48%\n",
      "Random forest Accuracy: 80.60%\n",
      "Random forest Accuracy: 83.96%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_set(0.3)\n",
    "    lr = RandomForestClassifier(max_features=8, bootstrap=True, min_samples_split=9, n_estimators=14, criterion='entropy',\n",
    "                       min_samples_leaf=4, max_depth=None)  \n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"%s Accuracy: %.2f%%\" % (\"Random forest\", accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission, select the best model for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission score is 0.77990 better as than gender classifier 0.76555\n",
    "\n",
    "clf1 = RandomForestClassifier(max_features=8, bootstrap=True, min_samples_split=9, n_estimators=14, criterion='entropy',\n",
    "                       min_samples_leaf=4, max_depth=None)  \n",
    "clf1.fit(train_dataset_onehot, train_label)\n",
    "r_pred = clf1.predict(test_dataset_onehot)\n",
    "r_predictions = [int(round(value)) for value in r_pred]\n",
    "\n",
    "submission_df = pandas.DataFrame(index=test_dataset.index, columns=[\"Survived\"])\n",
    "submission_df[\"Survived\"] = r_predictions\n",
    "submission_df.to_csv(\"submission_best_rf.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission score is 0.77033 better than gender classifier 0.76555\n",
    "\n",
    "clf2 = XGBClassifier(learning_rate=0.1, subsample=0.8, colsample_bytree=0.6, gamma=0.2,\n",
    "                       max_depth=3, reg_alpha=0.1, min_child_weight=2, objective= 'binary:logistic')   \n",
    "clf2.fit(train_dataset_onehot, train_label)\n",
    "r_pred = clf2.predict(test_dataset_onehot)\n",
    "r_predictions = [int(round(value)) for value in r_pred]\n",
    "\n",
    "submission_df = pandas.DataFrame(index=test_dataset.index, columns=[\"Survived\"])\n",
    "submission_df[\"Survived\"] = r_predictions\n",
    "submission_df.to_csv(\"submission_best_xg.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission score is 0.76077 worser than gender classifier 0.76555\n",
    "\n",
    "clf3 = MultinomialNB(alpha = 0.75)\n",
    "clf3.fit(train_dataset_onehot, train_label)\n",
    "r_pred = clf3.predict(test_dataset_onehot)\n",
    "r_predictions = [int(round(value)) for value in r_pred]\n",
    "\n",
    "submission_df = pandas.DataFrame(index=test_dataset.index, columns=[\"Survived\"])\n",
    "submission_df[\"Survived\"] = r_predictions\n",
    "submission_df.to_csv(\"submission_best_mn.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission score is 0.77033 worser than gender classifier 0.76555\n",
    "\n",
    "clf4 = LogisticRegression(C = 0.25)\n",
    "clf4.fit(train_dataset_onehot, train_label)\n",
    "r_pred = clf4.predict(test_dataset_onehot)\n",
    "r_predictions = [int(round(value)) for value in r_pred]\n",
    "\n",
    "submission_df = pandas.DataFrame(index=test_dataset.index, columns=[\"Survived\"])\n",
    "submission_df[\"Survived\"] = r_predictions\n",
    "submission_df.to_csv(\"submission_best_lr.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission score is 0.77990 better than gender classifier 0.76555\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('rf', clf1), ('xgb', clf2), ('nb', clf3), ('lr', clf4)], voting='hard')\n",
    "eclf2.fit(train_dataset_onehot, train_label) \n",
    "r_pred = eclf2.predict(test_dataset_onehot)\n",
    "r_predictions = [int(round(value)) for value in r_pred]\n",
    "\n",
    "submission_df = pandas.DataFrame(index=test_dataset.index, columns=[\"Survived\"])\n",
    "submission_df[\"Survived\"] = r_predictions\n",
    "submission_df.to_csv(\"submission_best_voting.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
